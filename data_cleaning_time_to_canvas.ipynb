{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:06.926826Z",
     "start_time": "2020-07-04T21:01:06.384111Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:20.338964Z",
     "start_time": "2020-07-04T21:01:06.930259Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"/Users/stephan/Data_Science/Metis/Bootcamp/Data_project1/data_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the `EXITS` column contains trailing spaces, so we get rid of those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:20.353582Z",
     "start_time": "2020-07-04T21:01:20.343032Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data.columns = raw_data.columns.str.rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T21:07:21.552058Z",
     "start_time": "2020-07-01T21:07:21.534664Z"
    }
   },
   "source": [
    "Adding a Datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:27.619626Z",
     "start_time": "2020-07-04T21:01:20.358525Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cm4s0832G35p"
   },
   "outputs": [],
   "source": [
    "raw_data[\"DATE_TIME\"] = pd.to_datetime(raw_data.DATE + \" \" + raw_data.TIME, \n",
    "                                            format=\"%m/%d/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is organized by turnstile, but does not have a direct unique identifier for each turnstile. To create one we add the column `ID`, which concatenates into a unique turnstile ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:31.527034Z",
     "start_time": "2020-07-04T21:01:27.622154Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_data[\"ID\"] = raw_data['C/A']+raw_data['UNIT']+raw_data['SCP']+raw_data['STATION']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains duplicates, so we deal with those next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:44.448413Z",
     "start_time": "2020-07-04T21:01:31.530172Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xrmUE6NWG36O"
   },
   "outputs": [],
   "source": [
    "# Get rid of the duplicate entries\n",
    "raw_data.sort_values([\"ID\", \"DATE_TIME\"], \n",
    "                          inplace=True, ascending=False)\n",
    "raw_data.drop_duplicates(subset=[\"ID\", \"DATE_TIME\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our design phase we decided to give our recommendations to the client in the form of stations to canvas, so we will group our data by station. We also move towards daily entries and exits instead of per 4 hours.\n",
    "\n",
    "The data given for `ENTRIES` and `EXITS` is cumulative, so aggregating by the first value for each day gives us the cumulative count at the start of each day. We then calculate the difference between days to get the daily numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:01:47.641042Z",
     "start_time": "2020-07-04T21:01:44.451009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b79019d558d4>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  data_by_station = raw_data.groupby(['STATION','ID','DATE'])['ENTRIES', 'EXITS'].first().diff()\n"
     ]
    }
   ],
   "source": [
    "data_by_station = raw_data.groupby(['STATION','ID','DATE'])['ENTRIES', 'EXITS'].first().diff()\n",
    "data_by_station.dropna(subset=[\"ENTRIES\",\"EXITS\"], axis=0, inplace=True)\n",
    "data_by_station.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First analysis of the resulting data shows some problems\n",
    "* negative values, indicating turnstile tickers that count down instead of up\n",
    "* Very large values that indicate a reset of a ticker\n",
    "\n",
    "We take the absolute values for the negative ticker data and set a limit for the maximum reasonable value of people going through a turnstile. Our limit is based on a max of 1 person per second, or 86400 a day. Anything higher than this number, we replace it with the mean for the rest of the values for that turnstile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:02:55.703549Z",
     "start_time": "2020-07-04T21:01:47.645317Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_daily_counts_entries(row, max_counter):\n",
    "    if row[\"ENTRIES\"] < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        row[\"ENTRIES\"] = abs(row[\"ENTRIES\"])\n",
    "    if row[\"ENTRIES\"] > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        row[\"ENTRIES\"] = np.nan\n",
    "    return row[\"ENTRIES\"]\n",
    "\n",
    "data_by_station[\"ENTRIES\"] = data_by_station.apply(get_daily_counts_entries, axis=1, max_counter=86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:04:03.563375Z",
     "start_time": "2020-07-04T21:02:55.706506Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_daily_counts_exits(row, max_counter):\n",
    "    if row[\"EXIT\"] < 0:\n",
    "        # Maybe counter is reversed?\n",
    "        row[\"EXIT\"] = abs(row[\"EXIT\"])\n",
    "    if row[\"ENTRIES\"] > max_counter:\n",
    "        # Check it again to make sure we're not still giving a counter that's too big\n",
    "        row[\"EXIT\"] = np.nan\n",
    "    return row[\"EXIT\"]\n",
    "\n",
    "data_by_station[\"EXITS\"] = data_by_station.apply(get_daily_counts_entries, axis=1, max_counter=86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the extremely large values from resets with the mean for that turnstile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:04:03.953357Z",
     "start_time": "2020-07-04T21:04:03.565769Z"
    }
   },
   "outputs": [],
   "source": [
    "data_by_station['ENTRIES'] = data_by_station['ENTRIES'].fillna(data_by_station.groupby('ID')['ENTRIES'].transform('mean'))\n",
    "data_by_station['EXITS'] = data_by_station['EXITS'].fillna(data_by_station.groupby('ID')['EXITS'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For canvassing we are interested in total traffic, so we add up entries and exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:04:03.971938Z",
     "start_time": "2020-07-04T21:04:03.955864Z"
    }
   },
   "outputs": [],
   "source": [
    "data_by_station[\"TRAFFIC\"] = data_by_station.ENTRIES + data_by_station.EXITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T21:04:16.027179Z",
     "start_time": "2020-07-04T21:04:03.974284Z"
    }
   },
   "outputs": [],
   "source": [
    "data_by_station.to_csv('data_2019_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
